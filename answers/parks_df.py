import sys
from pyspark.sql import SparkSession

file_name = sys.argv[1]

spark = SparkSession.builder.master("local").appName("lab1").getOrCreate()

df = spark.read.csv(file_name, header = True)

print(df.filter(df['Nom_parc'] != '').count())